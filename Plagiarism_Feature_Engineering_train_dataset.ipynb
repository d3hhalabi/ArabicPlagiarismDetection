{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4903f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import helper_Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913535b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a csv file and return a transformed dataframe\n",
    "def numerical_dataframe(csv_file):    \n",
    "    df = pd.read_csv(csv_file, index_col=0)\n",
    "    \n",
    "    df['Class'] = df['plagiarism_types'].map({'no-plagiarism':0,\n",
    "                                      'artificial-obfuscation':1,\n",
    "                                      'no-obfuscation':1,\n",
    "                                      'simulated-obfuscation':1})\n",
    "    \n",
    "    df['category'] = df['plagiarism_types']\n",
    "    \n",
    "    df['category'] = df['category'].map({'no-plagiarism':0,\n",
    "                                      'artificial-obfuscation':1,\n",
    "                                      'no-obfuscation':2,\n",
    "                                      'simulated-obfuscation':3})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65793adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ngram containment for one answer file/source file pair in a df\n",
    "def calculate_containment(n, suspicious_text, source_text):    \n",
    "    #count the n-grams\n",
    "    counts = CountVectorizer(analyzer='word', ngram_range=(n,n))\n",
    "    ngrams_array = counts.fit_transform([suspicious_text, source_text]).toarray()\n",
    "    \n",
    "    #containment calculation\n",
    "    containment = (np.minimum(ngrams_array[0],ngrams_array[1]).sum())/(ngrams_array[0].sum())\n",
    "    \n",
    "    return containment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10d23a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the normalized LCS given an suspicious text and a source text\n",
    "def lcs_norm_word(suspicious_text, source_text):\n",
    "    '''Computes the longest common subsequence of words in two texts; returns a normalized value.\n",
    "       :param suspicious_text: The pre-processed text for an answer text\n",
    "       :param source_text: The pre-processed text for an answer's associated source text\n",
    "       :return: A normalized LCS value'''\n",
    "    \n",
    "    #split the strings into words using split() and whitespace as a separator\n",
    "    suspicious_words = suspicious_text.split()\n",
    "    source_words = source_text.split()\n",
    "    \n",
    "    #getting the word counts\n",
    "    suspicious_w_counts = len(suspicious_words)\n",
    "    source_w_counts = len(source_words)\n",
    "    \n",
    "    #instantiating a matrix adding extra row and column of zeros\n",
    "    lcs_matrix = np.zeros((source_w_counts + 1, suspicious_w_counts + 1), dtype=int)\n",
    "    \n",
    "    #fillling up the matrix based on matches\n",
    "    for s, s_word in enumerate(source_words, 1):\n",
    "        for a, a_word in enumerate(suspicious_words, 1):\n",
    "            if s_word == a_word:\n",
    "                lcs_matrix[s][a] = lcs_matrix[s-1][a-1] + 1\n",
    "            else:\n",
    "                lcs_matrix[s][a] = max(lcs_matrix[s-1][a], lcs_matrix[s][a-1])\n",
    "    \n",
    "    lcs = lcs_matrix[source_w_counts][suspicious_w_counts]        \n",
    "        \n",
    "    return lcs/suspicious_w_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c4d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'data/train-pair-sentences.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6afff259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = numerical_dataframe(csv_file)\n",
    "df_transformed.drop(columns='obfuscation_types', axis=1, inplace=True)\n",
    "#df_transformed = df_transformed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36aedaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plagiarism_types</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial-obfuscation</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-obfuscation</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-plagiarism</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simulated-obfuscation</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         plagiarism_types  Counts\n",
       "0  artificial-obfuscation     838\n",
       "1          no-obfuscation     696\n",
       "2           no-plagiarism     169\n",
       "3   simulated-obfuscation     191"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts_per_plagiarism_type = df_transformed.groupby(['plagiarism_types']).size().reset_index(name=\"Counts\")\n",
    "display(counts_per_plagiarism_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ef86b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'suspicious_text'\n",
    "\n",
    "df_transformed = helper_Arabic.complete_preprocess(df_transformed, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51075bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'source_text'\n",
    "\n",
    "df_transformed = helper_Arabic.complete_preprocess(df_transformed, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee69303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_text(text):\n",
    "    str_text = str(text)\n",
    "    len_text = len(str_text)\n",
    "    \n",
    "    return len_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "285d3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_words(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40d6f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed['len_suspicious_text'] = df_transformed['suspicious_text'].apply(lambda x: len_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a96b71ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed['len_source_text'] = df_transformed['source_text'].apply(lambda x: len_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58991708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed['num_words_suspicious_text'] = df_transformed['suspicious_text'].apply(lambda x: num_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "115ecd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed['num_words_source_text'] = df_transformed['source_text'].apply(lambda x: num_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a0f63fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_task(df):\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    #df_temp = df_temp[df_temp['plagiarism_types'] == plagiarism_type]\n",
    "    #df_temp = df_temp.head(10)\n",
    "    df_temp.reset_index(drop=True, inplace=True)\n",
    "    print(df_temp.shape)\n",
    "\n",
    "    n_grams = range(1,8)\n",
    "\n",
    "    containment_values = []\n",
    "    lcs_values = []\n",
    "    col_names = []\n",
    "\n",
    "    for n_gram in n_grams:\n",
    "        col_name = 'c_' + str(n_gram)\n",
    "        col_names.append(col_name)\n",
    "\n",
    "    col_names.append('lcs_value')\n",
    "\n",
    "    df_features = pd.DataFrame(columns = col_names)\n",
    "\n",
    "    for row_i in df_temp.index:\n",
    "        suspicious_text = df_temp.iloc[row_i]['suspicious_text']\n",
    "        source_text = df_temp.iloc[row_i]['source_text']\n",
    "        \n",
    "        if len(suspicious_text) < 5:\n",
    "            print(row_i)\n",
    "            continue\n",
    "\n",
    "        if len(source_text) < 5:\n",
    "            print(row_i)\n",
    "            continue\n",
    "            \n",
    "        features_values = []\n",
    "\n",
    "        for n_gram in n_grams:\n",
    "            containment_value = calculate_containment(n_gram, suspicious_text, source_text)\n",
    "            features_values.append(containment_value)\n",
    "\n",
    "        lcs_value = lcs_norm_word(suspicious_text, source_text)\n",
    "        features_values.append(lcs_value)\n",
    "        df_x = pd.DataFrame([features_values], columns = col_names)\n",
    "\n",
    "        df_features = df_features.append(df_x, ignore_index = True)\n",
    "        \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d980571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1894, 9)\n"
     ]
    }
   ],
   "source": [
    "df_features_artificial_obfuscation = perform_task(df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58a05566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_features_artificial_obfuscation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccc7adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_features.corr().abs().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edb4b7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>lcs_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c_1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_2</th>\n",
       "      <td>0.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_3</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_4</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_5</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_6</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_7</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcs_value</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            c_1   c_2   c_3   c_4   c_5   c_6   c_7  lcs_value\n",
       "c_1        1.00  0.37  0.36  0.36  0.36  0.36  0.36       0.34\n",
       "c_2        0.37  1.00  0.99  0.98  0.96  0.94  0.93       0.91\n",
       "c_3        0.36  0.99  1.00  1.00  0.99  0.97  0.96       0.92\n",
       "c_4        0.36  0.98  1.00  1.00  1.00  0.99  0.98       0.92\n",
       "c_5        0.36  0.96  0.99  1.00  1.00  1.00  0.99       0.92\n",
       "c_6        0.36  0.94  0.97  0.99  1.00  1.00  1.00       0.92\n",
       "c_7        0.36  0.93  0.96  0.98  0.99  1.00  1.00       0.91\n",
       "lcs_value  0.34  0.91  0.92  0.92  0.92  0.92  0.91       1.00"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "824b6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['c_1', 'c_2', 'c_7', 'lcs_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "941e4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df_features[selected_features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "27cf1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_transformed['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ceca447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1894,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dcfe6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(x, y, filename):   \n",
    "    \n",
    "    # in this concatenation the first column will be my labels, the remaining columns are features\n",
    "    pd.concat([pd.DataFrame(y), pd.DataFrame(x)], axis=1).to_csv(filename, header=False, index=False)\n",
    "\n",
    "    print('file created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "baf0800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file created\n"
     ]
    }
   ],
   "source": [
    "file_name = 'train.csv'\n",
    "make_csv(train_x, train_y, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4640a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19603c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0ec51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac37baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2becde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
