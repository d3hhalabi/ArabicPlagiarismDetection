{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5057eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e50a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Read in csv training dataset\n",
    "dataset_dir = 'data2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8933e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = 'train_multi_class.csv'\n",
    "#training_file = 'train.csv'\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(dataset_dir, training_file), header=None, names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97eaddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1894, 4)\n",
      "(1894,)\n"
     ]
    }
   ],
   "source": [
    "# Divide data into features X and target (Classes) Y\n",
    "train_y = df_train.iloc[:,0]\n",
    "train_x = df_train.iloc[:,1:]\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a41e70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv training dataset\n",
    "testing_file = 'test_multi_class.csv'\n",
    "#testing_file = 'test.csv'\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(dataset_dir, testing_file), header=None, names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12cd719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1896, 4)\n",
      "(1896,)\n"
     ]
    }
   ],
   "source": [
    "# Divide data into features X and target (Classes) Y\n",
    "test_y = df_test.iloc[:,0]\n",
    "test_x = df_test.iloc[:,1:]\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ac4a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define baseline model. Then use it in Keras Classifier for the training\n",
    "def baseline_model():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_shape=(4,), activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "    model.add(Dense(4, activation = 'relu'))\n",
    "    model.add(Dense(4, activation = 'softmax')) # Softmax for multi-class classification\n",
    "    # Compile model here\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e205d957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204c4d28a60>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "33d7fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d0efa331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_y = model.predict_classes(test_x)\n",
    "pred_y = model.predict(test_x) \n",
    "pred_classes1 = np.argmax(pred_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9f71c4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 3.7050 - accuracy: 0.4251\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eeac4b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         no-plagiarism       0.90      0.47      0.62       169\n",
      "artificial-obfuscation       0.47      0.52      0.50       840\n",
      "        no-obfuscation       0.33      0.41      0.36       696\n",
      " simulated-obfuscation       0.00      0.00      0.00       191\n",
      "\n",
      "              accuracy                           0.43      1896\n",
      "             macro avg       0.42      0.35      0.37      1896\n",
      "          weighted avg       0.41      0.43      0.41      1896\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_y, pred_classes1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ccc8d97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0446 - accuracy: 0.4283\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         no-plagiarism       0.88      0.55      0.68       169\n",
      "artificial-obfuscation       0.47      0.49      0.48       840\n",
      "        no-obfuscation       0.33      0.44      0.38       696\n",
      " simulated-obfuscation       0.00      0.00      0.00       191\n",
      "\n",
      "              accuracy                           0.43      1896\n",
      "             macro avg       0.42      0.37      0.38      1896\n",
      "          weighted avg       0.41      0.43      0.41      1896\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=100, batch_size=50, verbose=0)\n",
    "\n",
    "#pred_y = model.predict_classes(test_x)\n",
    "pred_y = model.predict(test_x) \n",
    "pred_classes1 = np.argmax(pred_y, axis=1)\n",
    "\n",
    "score = model.evaluate(test_x, test_y, verbose=1)\n",
    "print()\n",
    "\n",
    "print(classification_report(test_y, pred_classes1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "82be3855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 4.2723 - accuracy: 0.4035\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         no-plagiarism       0.85      0.26      0.40       169\n",
      "artificial-obfuscation       0.47      0.50      0.48       840\n",
      "        no-obfuscation       0.32      0.44      0.37       696\n",
      " simulated-obfuscation       0.00      0.00      0.00       191\n",
      "\n",
      "              accuracy                           0.40      1896\n",
      "             macro avg       0.41      0.30      0.31      1896\n",
      "          weighted avg       0.40      0.40      0.38      1896\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=100, batch_size=50, verbose=0)\n",
    "\n",
    "#pred_y = model.predict_classes(test_x)\n",
    "pred_y = model.predict(test_x) \n",
    "pred_classes1 = np.argmax(pred_y, axis=1)\n",
    "\n",
    "score = model.evaluate(test_x, test_y, verbose=1)\n",
    "print()\n",
    "\n",
    "print(classification_report(test_y, pred_classes1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "efeced20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 4.2532 - accuracy: 0.4119\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         no-plagiarism       0.87      0.31      0.45       169\n",
      "artificial-obfuscation       0.48      0.48      0.48       840\n",
      "        no-obfuscation       0.33      0.46      0.38       696\n",
      " simulated-obfuscation       0.00      0.00      0.00       191\n",
      "\n",
      "              accuracy                           0.41      1896\n",
      "             macro avg       0.42      0.31      0.33      1896\n",
      "          weighted avg       0.41      0.41      0.39      1896\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=100, batch_size=30, verbose=0)\n",
    "\n",
    "#pred_y = model.predict_classes(test_x)\n",
    "pred_y = model.predict(test_x) \n",
    "pred_classes1 = np.argmax(pred_y, axis=1)\n",
    "\n",
    "score = model.evaluate(test_x, test_y, verbose=1)\n",
    "print()\n",
    "\n",
    "print(classification_report(test_y, pred_classes1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fdaac6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 4.6210 - accuracy: 0.3982\n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         no-plagiarism       0.95      0.11      0.20       169\n",
      "artificial-obfuscation       0.48      0.49      0.48       840\n",
      "        no-obfuscation       0.32      0.47      0.38       696\n",
      " simulated-obfuscation       0.00      0.00      0.00       191\n",
      "\n",
      "              accuracy                           0.40      1896\n",
      "             macro avg       0.44      0.27      0.27      1896\n",
      "          weighted avg       0.41      0.40      0.37      1896\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=200, batch_size=5, verbose=0)\n",
    "\n",
    "#pred_y = model.predict_classes(test_x)\n",
    "pred_y = model.predict(test_x) \n",
    "pred_classes1 = np.argmax(pred_y, axis=1)\n",
    "\n",
    "score = model.evaluate(test_x, test_y, verbose=1)\n",
    "print()\n",
    "\n",
    "print(classification_report(test_y, pred_classes1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee25ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
